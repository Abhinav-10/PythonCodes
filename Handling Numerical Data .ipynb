{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Numerical Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xi′ =(xi − min (x))/(max (x) − min (x)})   # Formula runs at \n",
    "# x   -->  the feature vector\n",
    "# Xi' -->  is the rescaled element\n",
    "\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "# Create feature\n",
    "feature = np.array([[-500.5],\n",
    "[-100.1],\n",
    "[0],\n",
    "[100.1],\n",
    "[900.9]])\n",
    "# Create scaler\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "# Scale feature\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "# Show feature\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xi′=(xi − x')/σ\n",
    "# x' --> mean\n",
    "# σ  --> standard deviation \n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "# Create feature\n",
    "x = np.array([[-1000.1],\n",
    "[-200.2],\n",
    "[500.5],\n",
    "[600.6],\n",
    "[9000.9]])\n",
    "# Create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Transform the feature\n",
    "standardized = scaler.fit_transform(x)\n",
    "# Show feature\n",
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0\n",
      "Standard deviation: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print mean and standard deviation\n",
    "print(\"Mean:\", round(standardized.mean()))\n",
    "print(\"Standard deviation:\", standardized.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create scaler\n",
    "robust_scaler = preprocessing.RobustScaler()\n",
    "# Transform feature\n",
    "robust_scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ∥ x ∥ 2 = sqrt(x 2 1 + x 2 2 + ⋯ + x 2 n)\n",
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "# Create feature matrix\n",
    "features = np.array([[0.5, 0.5],\n",
    "[1.1, 3.4],\n",
    "[1.5, 20.2],\n",
    "[1.63, 34.4],\n",
    "[10.9, 3.3]])\n",
    "# Create normalizer\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "# Transform feature matrix\n",
    "normalizer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eucledian Norm\n",
    "# Transform feature matrix\n",
    "features_l2_norm = Normalizer(norm=\"l2\").transform(features)\n",
    "# Show feature matrix\n",
    "features_l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#manthon norm\n",
    "# ∥ x ∥ 1 =\n",
    "# n\n",
    "# ∑ xi\n",
    "# i =1\n",
    "\n",
    "# Transform feature matrix\n",
    "features_l1_norm = Normalizer(norm=\"l1\").transform(features)\n",
    "# Show feature matrix\n",
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of the first observation's values: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print sum\n",
    "print(\"Sum of the first observation\\'s values:\",\n",
    "features_l1_norm[0, 0] + features_l1_norm[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.],\n",
       "       [2., 3., 4., 6., 9.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    "[2, 3],\n",
    "[2, 3]])\n",
    "# Create PolynomialFeatures object\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "# Create polynomial features\n",
    "polynomial_interaction.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 3., 6.],\n",
       "       [2., 3., 6.],\n",
       "       [2., 3., 6.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction = PolynomialFeatures(degree=2,\n",
    "interaction_only=True, include_bias=False)\n",
    "interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    "[2, 3],\n",
    "[2, 3]])\n",
    "# Define a simple function\n",
    "def add_ten(x):\n",
    "    return x + 10\n",
    "# Create transformer\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "# Transform feature matrix\n",
    "ten_transformer.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0         12         13\n",
       "1         12         13\n",
       "2         12         13"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "df.apply(add_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1,  1, -1, -1,  1,  1, -1,  1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs\n",
    "# Create simulated data\n",
    "features, _ = make_blobs(n_samples = 10,\n",
    "n_features = 2,\n",
    "centers = 1,\n",
    "random_state = 1)\n",
    "# Replace the first observation's values with extreme values\n",
    "features[0,0] = 10000\n",
    "features[0,1] = 10000\n",
    "# Create detector\n",
    "outlier_detector = EllipticEnvelope(contamination=.5)\n",
    "# Fit detector\n",
    "outlier_detector.fit(features)\n",
    "# Predict outliers\n",
    "outlier_detector.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create one feature\n",
    "feature = features[:,0]\n",
    "# Create a function to return index of outliers\n",
    "def indicies_of_outliers(x):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "#     print(q1, 13)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (iqr * 1.5)\n",
    "    upper_bound = q3 + (iqr * 1.5)\n",
    "    return np.where((x > upper_bound) | (x < lower_bound))\n",
    "# Run function\n",
    "indicies_of_outliers(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Bathrooms  Square_Feet\n",
       "0  534433        2.0         1500\n",
       "1  392333        3.5         2500\n",
       "2  293222        2.0         1500\n",
       "4   24342        0.0        42423"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 handling of outliers\n",
    "# Load library\n",
    "import pandas as pd\n",
    "# Create DataFrame\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [534433, 392333, 293222, 4322032, 24342]\n",
    "houses['Bathrooms'] = [2, 3.5, 2, 116, 0]\n",
    "houses['Square_Feet'] = [1500, 2500, 1500, 48000, 42423]\n",
    "# Filter observations\n",
    "houses[houses['Bathrooms'] < 20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier\n",
       "0   534433        2.0         1500        0\n",
       "1   392333        3.5         2500        0\n",
       "2   293222        2.0         1500        0\n",
       "3  4322032      116.0        48000        1\n",
       "4    24342        0.0        42423        0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import numpy as np\n",
    "# Create feature based on boolean condition\n",
    "houses[\"Outlier\"] = np.where(houses[\"Bathrooms\"] < 20, 0, 1)\n",
    "# Show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "      <th>Log_Of_Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.778956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42423</td>\n",
       "      <td>0</td>\n",
       "      <td>10.655446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier  Log_Of_Square_Feet\n",
       "0   534433        2.0         1500        0            7.313220\n",
       "1   392333        3.5         2500        0            7.824046\n",
       "2   293222        2.0         1500        0            7.313220\n",
       "3  4322032      116.0        48000        1           10.778956\n",
       "4    24342        0.0        42423        0           10.655446"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log feature\n",
    "houses[\"Log_Of_Square_Feet\"] = [np.log(x) for x in houses[\"Square_Feet\"]]\n",
    "# Show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Binarizer\n",
    "# Create feature\n",
    "age = np.array([[6],\n",
    "[12],\n",
    "[20],\n",
    "[36],\n",
    "[65]])\n",
    "# Create binarizer\n",
    "binarizer = Binarizer(18)\n",
    "# Transform feature\n",
    "binarizer.fit_transform(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin feature\n",
    "np.digitize(age, bins=[20,30,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  group\n",
       "0  -9.877554  -3.336145      2\n",
       "1  -7.287210  -8.353986      0\n",
       "2  -6.943061  -7.023744      0\n",
       "3  -7.440167  -8.791959      0\n",
       "4  -6.641388  -8.075888      0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "# Make simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 50,\n",
    "n_features = 2,\n",
    "centers = 3,\n",
    "random_state = 1)\n",
    "# Create DataFrame\n",
    "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "# Make k-means clusterer\n",
    "clusterer = KMeans(3, random_state=0)\n",
    "# Fit clusterer\n",
    "clusterer.fit(features)\n",
    "# Predict values\n",
    "dataframe[\"group\"] = clusterer.predict(features)\n",
    "# View first few observations\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 11.1],\n",
       "       [ 2.2, 22.2],\n",
       "       [ 3.3, 33.3],\n",
       "       [ 4.4, 44.4]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import numpy as np\n",
    "# Create feature matrix\n",
    "features = np.array([[1.1, 11.1],\n",
    "[2.2, 22.2],\n",
    "[3.3, 33.3],\n",
    "[4.4, 44.4],\n",
    "[np.nan, 55]])\n",
    "# Keep only observations that are not (denoted by ~) missing\n",
    "features[~np.isnan(features).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0        1.1       11.1\n",
       "1        2.2       22.2\n",
       "2        3.3       33.3\n",
       "3        4.4       44.4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "import pandas as pd\n",
    "# Load data\n",
    "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "# Remove observations with missing values\n",
    "dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fancyimpute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-9b75deec0c8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfancyimpute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fancyimpute'"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from fancyimpute import KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "# Make a simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "n_features = 2,\n",
    "random_state = 1)\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n",
    "# Replace the first feature's first value with a missing value\n",
    "true_value = standardized_features[0,0]\n",
    "standardized_features[0,0] = np.nan\n",
    "# Predict the missing values in the feature matrix\n",
    "features_knn_imputed = KNN(k=5, verbose=0).complete(standardized_features)\n",
    "# Compare true and imputed values\n",
    "print(\"True Value:\", true_value)\n",
    "print(\"Imputed Value:\", features_knn_imputed[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fancyimpute\n",
      "  Downloading fancyimpute-0.5.4.tar.gz (20 kB)\n",
      "Collecting knnimpute\n",
      "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.10 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from fancyimpute) (1.18.1)\n",
      "Requirement already satisfied: scipy in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from fancyimpute) (1.4.1)\n",
      "Collecting cvxpy>=1.0.6\n",
      "  Downloading cvxpy-1.0.31.tar.gz (947 kB)\n",
      "\u001b[K     |████████████████████████████████| 947 kB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.2 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from fancyimpute) (0.22.2.post1)\n",
      "Requirement already satisfied: keras>=2.0.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from fancyimpute) (2.3.1)\n",
      "Requirement already satisfied: tensorflow in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from fancyimpute) (2.2.0rc4)\n",
      "Requirement already satisfied: six in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from knnimpute->fancyimpute) (1.14.0)\n",
      "Collecting scs>=1.1.3\n",
      "  Downloading scs-2.1.2.tar.gz (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.9.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ecos>=2\n",
      "  Downloading ecos-2.0.7.post1.tar.gz (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 5.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting osqp>=0.4.1\n",
      "  Downloading osqp-0.6.1-cp38-cp38-manylinux1_x86_64.whl (164 kB)\n",
      "\u001b[K     |████████████████████████████████| 164 kB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from scikit-learn>=0.21.2->fancyimpute) (0.14.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from keras>=2.0.0->fancyimpute) (1.0.8)\n",
      "Requirement already satisfied: h5py in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from keras>=2.0.0->fancyimpute) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from keras>=2.0.0->fancyimpute) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from keras>=2.0.0->fancyimpute) (5.3.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (1.12.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (1.6.3)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (0.3.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (3.2.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (2.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (2.2.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (1.28.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (3.11.3)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (0.9.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorflow->fancyimpute) (0.34.2)\n",
      "Requirement already satisfied: dill>=0.3.1 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from multiprocess->cvxpy>=1.0.6->fancyimpute) (0.3.1.1)\n",
      "Requirement already satisfied: future in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from osqp>=0.4.1->cvxpy>=1.0.6->fancyimpute) (0.18.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (0.4.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (1.14.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (3.2.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (1.6.0.post3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (46.1.1.post20200323)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (2018.4.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (1.25.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (4.1.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (3.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/abhinavtripathi/anaconda3/envs/my_env/lib/python3.8/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->fancyimpute) (0.4.8)\n",
      "Building wheels for collected packages: fancyimpute, knnimpute, cvxpy, scs, multiprocess, ecos\n",
      "  Building wheel for fancyimpute (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fancyimpute: filename=fancyimpute-0.5.4-py3-none-any.whl size=26387 sha256=95bb447a67fa39456bc7afae7bb46426f59e33a6975ebab60100d6e258c76870\n",
      "  Stored in directory: /home/abhinavtripathi/.cache/pip/wheels/c5/ec/a7/b88763af756d0eed56208f6f5d2646fffaddf8afea1ad41dab\n",
      "  Building wheel for knnimpute (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11353 sha256=027b342b2018fe8c83f6b618e4d1cb3316f8949c3fd530dc159e7e5e5e4c8e91\n",
      "  Stored in directory: /home/abhinavtripathi/.cache/pip/wheels/5f/e9/7a/9969b4e11eb626b45f12a46849b8c65aa718244a243583caf1\n",
      "  Building wheel for cvxpy (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cvxpy: filename=cvxpy-1.0.31-cp38-cp38-linux_x86_64.whl size=2183163 sha256=c5a01430cb63d05c914258eba157953021a4276a2d6650924869f9f9da7d2347\n",
      "  Stored in directory: /home/abhinavtripathi/.cache/pip/wheels/34/52/48/b508e16900d18b1f1fd56278003e6b4e110be549f158a333b5\n",
      "  Building wheel for scs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scs: filename=scs-2.1.2-cp38-cp38-linux_x86_64.whl size=507933 sha256=791e5f281ad16860954f20664eab14697828585008e3df6a5aa4aef5bdb66b2d\n",
      "  Stored in directory: /home/abhinavtripathi/.cache/pip/wheels/64/b7/4b/a5c555c1d94b8a25ac3f9da1bdd19ba9896f558d124de7d7ef\n",
      "  Building wheel for multiprocess (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multiprocess: filename=multiprocess-0.70.9-py3-none-any.whl size=125258 sha256=06ab9b95e456a0165c14dd739121ec251870f9d1b1226c21a9072143ff0ad973\n",
      "  Stored in directory: /home/abhinavtripathi/.cache/pip/wheels/e6/a9/de/b8baac8a1d74e363e93fd1c83662ce752c671cb68b5dee8c30\n",
      "  Building wheel for ecos (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ecos: filename=ecos-2.0.7.post1-cp38-cp38-linux_x86_64.whl size=206640 sha256=c0ce810566e86f3dc56a0d5f14501062655fea633d8d4fcead65b454f9970388\n",
      "  Stored in directory: /home/abhinavtripathi/.cache/pip/wheels/c3/c1/ce/b551b0b3a40c990e1da2ec9aecff62f7c2d43cab8766368e82\n",
      "Successfully built fancyimpute knnimpute cvxpy scs multiprocess ecos\n",
      "Installing collected packages: knnimpute, scs, multiprocess, ecos, osqp, cvxpy, fancyimpute\n",
      "Successfully installed cvxpy-1.0.31 ecos-2.0.7.post1 fancyimpute-0.5.4 knnimpute-0.1.0 multiprocess-0.70.9 osqp-0.6.1 scs-2.1.2\n"
     ]
    }
   ],
   "source": [
    "! pip install fancyimpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
